# 前言
大模型的性能评测成为了衡量其实际效能的不可或缺的一环。随着深度学习技术的迅猛发展，各种领域都涌现出了众多庞大的模型，它们在语言理解、图像识别、自然语言处理等任务中展现出强大的潜力。然而，要充分了解一个大模型的性能，仅仅依靠理论分析远远不够，而使用数据集进行评测则成为最为直观而准确的方式之一。

数据集作为性能评测的基石，发挥着至关重要的作用。这其中存在着两种主要类型的数据集：开源数据集和私有数据集。大模型服务商通常会在外部公布其使用的开源数据集，以便更广泛地展示其性能。然而，事实上，这些服务商在内部往往也会拥有一套私有数据集，用于更全面、深入地评估模型在特定场景下的表现。

尽管开源数据集为用户提供了一个方便的起点，但由于其广泛性，可能并不总能够完全适应个性化的产品场景。因此，建立和使用自己的私有数据集显得尤为重要，以确保性能评测更贴近实际应用需求。

在大模型竞技中，开源数据集的使用也带来了一些问题，其中之一就是“刷分”现象。一些模型可能专门针对开源数据集进行训练，以获取更高的性能分数，而这并不一定反映其在真实场景中的表现。因此，对于性能评测而言，关注模型在私有数据集上的表现，以及其在特定领域的适应性，显得尤为重要。

# mmlu
MMLU（大规模多任务语言理解） 是一个综合性的基准，用于评估语言模型在各种自然语言理解任务上的表现。它涵盖了数学、物理、历史、法律、医学等57个科目的测试集。MMLU的核心设计理念是全面评估预训练模型在知识掌握、推理和问题解决方面的能力。数据特点是涵盖知识面在科目和难度上比较广泛。MMLU采用选择题的形式进行评估，让模型从四个选项中选择最佳答案。

[数据集地址](https://paperswithcode.com/dataset/mmlu)

例子：

```
{
  "question": "What is the embryological origin of the hyoid bone?",
  "choices": ["The first pharyngeal arch", "The first and second pharyngeal arches", "The second pharyngeal arch", "The second and third pharyngeal arches"],
  "answer": "D"
}
```
