# prompt
中文可以翻译成提示或者指令。我们调用模型的时候，需要输入问题、指令等等，这些输入就叫做prompt。

> 在文生图领域，prompt通常被翻译成提示词

由于模型本身的限制，它有时候并无法完全理解你的prompt，因此我们经常需要调试我们的prompt。

更智能的模型它越能理解你的指令，因此当你调试很多次prompt之后，模型依然无法理解你的指令，那么不妨换一种模型。

而且模型本身的也会有一定的不稳定性，所以我们的prompt有时候能够正常输出有时候不能正常输出，这种现象也是正常的。

遇见这种情况，通常可以多次强调你的某个指令，或者换另外一个模型。

## prompt的类型

prompt对于文生文模型来说，实际上就是一个字符串，这个字符串描述了你要让模型干的事情。

但是因为不同的服务商他们训练方式、对外提供API方式的不同，输入给模型的参数也会有不同。

但是在文生文领域，通常只有两种，一种是直接一段文本，一种是文本数组。

```
// 纯文本prompt展示
下面的内容是用户与模型的对话记录：
用户：1+1等于多少
模型：等于2
用户：再加上3呢？
模型：等于5

现在用户的问题为：再加上8呢
```

```
// 文本数组prompt展示(messages形式)
[
    {role:'system',content:'下面的内容是用户与模型的对话记录'},
    {role:'user',content:'1+1等于多少'},
    {role:'assistant',content:'等于2'},
    {role:'user',content:'再加上3呢？'},
    {role:'assistant',content:'等于5'},
    {role:'user',content:'再加上8呢'}
]
```

仔细观察上面两种prompt类型，会发现messages形式会比较清晰明了，而纯文本prompt则会更加自由。

messages对用户来说，输入变得更加简单，而且也会更加稳定。

> 实际上，对于messages形式的prompt，模型服务商在内部也会将其转换为纯文本的prompt。并且训练的时候也是使用这种格式化后的prompt进行训练，因此稳定性会比第一种好。

## 模型的记忆问题
很多人接触模型API之后，是使用服务商提供的网页版进行调用的。

因为网页版已经是一个成型的产品，所以新人会误以为模型本身已经有记忆能力（用户与模型的对话历史。）

但是其实不是的，模型本身是没有记忆能力的。模型的记忆能力，也是来自于Prompt本身。

所以你能够看到纯文本prompt，会发现我们需要将用户的对话历史也在prompt中给出，这样模型才能知道你们的对话历史。

## 模型的逻辑能力
很多新人刚开始接触大模型，会以为模型的逻辑能力非常强大，一上来就给出非常复杂的指令。

然后却往往得不到理想的答案。

实际上，大模型只是基于前面的内容预测后面的内容。在一个多维的空间中，当你给出指令之后，答案会落在某个区域范围内的。

这个答案空间会非常大，虽然更好的模型会将这个空间收敛，但是以目前最强大的模型，收敛之后的答案空间也是非常巨大。

因此想要获得你满意的答案，除了好的模型、好的prompt，合适的温度参数等等之后，还有另外一个好方法，就是给模型一定的思考时间。

这个思考时间，目前只有一种方式能够做到，就是在prompt中让模型在回答之前先思考下，并且给出一个位置让模型存放思考的地方。

```
// 让模型思考的例子
{你的问题}

请你按以下格式输出：
思考：在这里生成要如何回答用户的问题
回答：在这里放入你生成的内容
```

可以看到，让模型思考需要花费一些额外的token，思考并不是免费的。

## promptValue
因为是我的笔记，所以上面的内容有点扯远了。

更前面的小节说到，prompt有两种类型，纯文本和文本数组的形式。

langchain提供了一个类：promptValue。

这个类内部会有一个输出成纯文本prompt和一个输出成文本数组prompt的方法。也就是说在这两个之后再封装一个类，用来兼容这两种情况。

## promptTemplate

promptTemplate又是什么鬼呢。

我们作为开发者，调试prompt很简单，但是要做一款面向用户的产品，prompt就不能太复杂。

但是不复杂的prompt往往又达不到我们的效果，因此我们需要将用户的输入内容再转换一下，转换为更加稳定的prompt。

这个就是promptTemplate，中文叫做指令模板或者提示模板，简单说就是类似于文本模板，用户的问题是文本模板中的变量。

比如之前的例子：
```
下面的内容是用户与模型的对话记录：
{chat_history}

现在用户的问题为：{user_input}
```

### messagePromptTemplate

跟之前的prompt类型一样，promptTemplate还需要一种能够兼容message类型的，它就是messagePromptTemplate。

实际上就是在promptTemplate的基础上，多一个role的字段而已。

### messagesPlaceholder
promptTemplate有变量，langchain在messages也引入了一个变量，它表示一段文本数组。

比如：
```
const chatHistory=[
    {role:'system',content:'下面的内容是用户与模型的对话记录'},
    {role:'user',content:'1+1等于多少'},
    {role:'assistant',content:'等于2'},
    {role:'user',content:'再加上3呢？'},
    {role:'assistant',content:'等于5'},
]
const prompt=[
    new MessagePlaceholder('chat_history'),
    {role:'user',content:'再加上8呢'}
]
```

这样历史记录就变成一个可传入的参数了，简单说就是在生成最终的文本数组之前，langchains会将两个数组拼接起来就是。

### ChatPromptTemplate

这个等价于messages，简单理解就是MessagePromptTemplate是数组的元素，ChatPromptTemplate就是messages这个数组。

# f-string
f-string 是 Python 中用于格式化字符串的一种方式。它是在 Python 3.6 版本中引入的。f-string 的名称来自于在字符串前加上 'f' 字母，表示这是一个格式化字符串。

使用 f-string，你可以在字符串中嵌入变量、表达式和函数调用，而无需使用传统的字符串格式化方法（如 `%` 操作符或 `str.format()` 方法）。这使得代码更简洁、可读性更强，并提供了更直观的语法。

以下是一个简单的示例，演示了使用 f-string 格式化字符串的方式：

```python
name = "Alice"
age = 30

# 使用 f-string 格式化字符串
message = f"Hello, my name is {name} and I am {age} years old."

# 打印结果
print(message)
```

在上面的例子中，`{name}` 和 `{age}` 是 f-string 的表达式部分，它们会被相应的变量值替代。f-string 还支持在表达式中执行任意的 Python 代码，使得字符串格式化更加灵活。

需要注意的是，f-string 只在 Python 3.6 及以上的版本中可用。如果你使用的是较旧的 Python 版本，你可能需要考虑其他字符串格式化的方法。

在langchainjs中，f-string则指能够变量（使用{}包裹）的字符串。

我们并不需要知道它具体是如何解析的，只要知道是什么就行。

> 个人感觉这个模板不太好用，哈哈。可能是为了兼容python，毕竟langchain一开始就是py的项目。

